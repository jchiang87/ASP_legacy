<?xml version="1.0" encoding="UTF-8"?>
<pipeline
   xmlns="http://glast-ground.slac.stanford.edu/pipeline"
   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
   xsi:schemaLocation="http://glast-ground.slac.stanford.edu/pipeline http://glast-ground.slac.stanford.edu/Pipeline-II/schemas/2.0/pipeline.xsd">
<!-- $Header$
-->
<task name="PGWave" version="4.8" type="Data">
  <variables>
    <!-- Default values that can be overridden at the command line. -->
    <var name="ST_INST">"/nfs/farm/g/glast/u30/builds/rh9_gcc32/ScienceTools/ScienceTools-v9r4p1"</var>
    <var name="BINDIR">rh9_gcc32</var>
  </variables>
  <prerequisites>
    <prerequisite name="logicalPath" type="string"/>
    <prerequisite name="OUTPUTDIR" type="string"/>
    <prerequisite name="frequency" type="string"/>
    <prerequisite name="interval" type="integer"/>
    <prerequisite name="TSTART" type="integer"/>
    <prerequisite name="TSTOP" type="integer"/>
    <prerequisite name="ASP_PATH" type="string"/>
    <prerequisite name="CATDIR" type="string"/>
    <prerequisite name="PGWAVEROOT" type="string"/>
  </prerequisites>

  <process name="catalogQuery">
    <script>
      <![CDATA[
        def query(outfile, path, TSTART, TSTOP):
            output = pipeline.createFile(outfile)
            opt1 = '(%(TSTART)i <= nMetStart && nMetStop <= %(TSTOP)i)' % locals()
            opt2 = '(nMetStart <= %(TSTART)i && %(TSTART)i <= nMetStop)' % locals()
            opt3 = '(nMetStart <= %(TSTOP)i && %(TSTOP)i <= nMetStop)' % locals()
            query = ('DataType == \"%s\" && (%s || %s || %s)' 
                     % (path, opt1, opt2, opt3))
            datasetList = datacatalog.getDatasets(logicalPath+'/*', query)
            datasetList.writeToFile(output, 1)
            pipeline.writeFile(output)
        query("Ft1FileList", "FT1", TSTART, TSTOP)
        query("Ft2FileList", "FT2", TSTART, TSTOP)
        ]]></script>
  </process>

  <process name="getPgwInputData">
    <job executable="${PGWAVEROOT}/${BINDIR}/getPgwInputData.sh"
         batchOptions=" -q short"/>
    <depends>
      <after process="catalogQuery" status="SUCCESS"/>
    </depends>
  </process>

  <process name="makeHealPixMaps">
    <job executable="${PGWAVEROOT}/${BINDIR}/makeHealPixMaps.sh"
         batchOptions="-q medium"/>
    <depends>
      <after process="getPgwInputData" status="SUCCESS"/>
    </depends>
  </process>

  <process name="runpgw">
    <job executable="${PGWAVEROOT}/${BINDIR}/runpgw.sh"
         batchOptions=" -q medium"/>
    <depends>
      <after process="makeHealPixMaps" status="SUCCESS"/>
    </depends>
  </process>

  <process name="registerData">
    <script><![CDATA[
    def filename(ext, suffix):
        fn = 'Filtered_evt' + ext
        tokens = fn.split('.')
        return tokens[0] + '_' + suffix + '.' + tokens[1]
    suffix = OUTPUTDIR.split('/')[-1]
    exts = ('.fits', '_map.fits', '_map.list', '_map.reg', 
            '_map_pgw_out.fits', '_map_ait.gif')
    files = [filename(ext, suffix) for ext in exts]
    files.append('counts_%s.fits' % suffix)
    files.append('exposure_%s.fits' % suffix)
    dataTypes = ('EVENTS', 'SKYMAP', 'PGWAVESOURCELIST', 'DS9REGIONS', 
                 'PGWAVESUMMARY', 'SKYMAP', 'COUNTSMAP', 'EXPOSUREMAP')
    priorProcess = pipeline.getProcessInstance("runpgw")
    processId = priorProcess.getVariable('ProcessInstance')
    print processId
    for outfile, dataType in zip(files, dataTypes):
        logicalPath = ('/ASP/OpsSim2/FlareMonitoring/%s/%s:%s' 
                       % (frequency, dataType, outfile))
        print logicalPath
        filePath = '%s/%s' % (OUTPUTDIR, outfile)
        print filePath
        #attributes = ('nProcessId=%s:nMetStart=%i:nMetStop=%i' 
        attributes = ('nDatasetId=%s:nMetStart=%i:nMetStop=%i' 
                      % (processId, TSTART, TSTOP))
        print attributes
        datacatalog.registerDataset(dataType, logicalPath, 
                                    filePath, attributes)
    if frequency in ('daily', 'weekly'):
        pipeline.createSubstream("drpMonitoring", 0, 
                                 "pgwave_processId=%i" % processId)
    ]]></script>
    <depends>
      <after process="runpgw" status="SUCCESS"/>
    </depends>
    <createsSubtasks>
      <subtask>drpMonitoring</subtask>
    </createsSubtasks>
  </process>
  
  <task name="drpMonitoring" version="1.0" type="Data">
    <prerequisites>
      <prerequisite name="pgwave_processId" type="integer"/>
    </prerequisites>
    <process name="launchDrpMonitoring">
      <job executable="${PGWAVEROOT}/${BINDIR}/launchDrpMonitoring.sh"
           batchOptions=" -q short"/>
    </process>
  </task><!--drpMonitoring-->

</task><!--PGWave-->
</pipeline>
