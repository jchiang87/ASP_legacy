<?xml version="1.0" encoding="UTF-8"?>
<pipeline
   xmlns="http://glast-ground.slac.stanford.edu/pipeline"
   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
   xsi:schemaLocation="http://glast-ground.slac.stanford.edu/pipeline http://glast-ground.slac.stanford.edu/Pipeline-II/schemas/2.0/pipeline.xsd">
<!-- $Header$
-->
<task name="PGWave" version="4.4" type="Data">
  <variables>
    <!-- Default values that can be overridden at the command line. -->
    <var name="ST_INST">"/nfs/farm/g/glast/u30/builds/rh9_gcc32/ScienceTools/ScienceTools-v9r4p1"</var>
    <var name="BINDIR">rh9_gcc32</var>
  </variables>
  <prerequisites>
    <prerequisite name="logicalPath" type="string"/>
    <prerequisite name="OUTPUTDIR" type="string"/>
    <prerequisite name="frequency" type="string"/>
    <prerequisite name="interval" type="integer"/>
    <prerequisite name="TSTART" type="integer"/>
    <prerequisite name="TSTOP" type="integer"/>
    <prerequisite name="ASP_PATH" type="string"/>
    <prerequisite name="CATDIR" type="string"/>
    <prerequisite name="PGWAVEROOT" type="string"/>
  </prerequisites>

  <process name="catalogQuery">
    <script>
      <![CDATA[
        def query(outfile, path, TSTART, TSTOP):
            output = pipeline.createFile(outfile)
            opt1 = '(%(TSTART)i <= nMetStart && nMetStop <= %(TSTOP)i)' % locals()
            opt2 = '(nMetStart <= %(TSTART)i && %(TSTART)i <= nMetStop)' % locals()
            opt3 = '(nMetStart <= %(TSTOP)i && %(TSTOP)i <= nMetStop)' % locals()
            query = ('DataType == \"%s\" && (%s || %s || %s)' 
                     % (path, opt1, opt2, opt3))
            datasetList = datacatalog.getDatasets(logicalPath+'/*', query)
            datasetList.writeToFile(output, 1)
            pipeline.writeFile(output)
        query("Ft1FileList", "FT1", TSTART, TSTOP)
        query("Ft2FileList", "FT2", TSTART, TSTOP)
        ]]></script>
  </process>

  <process name="getPgwInputData">
    <job executable="${PGWAVEROOT}/${BINDIR}/getPgwInputData.sh"
         batchOptions=" -q short"/>
    <depends>
      <after process="catalogQuery" status="SUCCESS"/>
    </depends>
  </process>

  <process name="makeHealPixMaps">
    <job executable="${PGWAVEROOT}/${BINDIR}/makeHealPixMaps.sh"
         batchOptions="-q medium"/>
    <depends>
      <after process="getPgwInputData" status="SUCCESS"/>
    </depends>
  </process>

  <process name="runpgw">
    <job executable="${PGWAVEROOT}/${BINDIR}/runpgw.sh"
         batchOptions=" -q medium"/>
    <depends>
      <after process="makeHealPixMaps" status="SUCCESS"/>
    </depends>
  </process>

  <process name="registerData">
    <script><![CDATA[
    suffix = OUTPUTDIR.split('/')[-1]
    rootname = 'Filtered_evt_%s' % suffix
    exts = ('.fits', '_map.fits', '_map.list', '_map.reg', 
            '_map_pgw_out.fits', '_map_ait.gif')
    files = [rootname + ext for ext in exts]
    files.append('counts_%s.fits' % suffix)
    files.append('exposure_%s.fits' % suffix)
    dataTypes = ('EVENTS', 'SKYMAP', 'PGWAVESOURCELIST', 'DS9REGIONS', 
                 'PGWAVESUMMARY', 'SKYMAP', 'COUNTSMAP', 'EXPOSUREMAP')
    thisProcess = pipeline.getProcessInstance("runpgw")
    print thisProcess
    processId = thisProcess.getVariable('PIPELINE_PROCESSINSTANCE')
    print PIPELINE_PROCESSINSTANCE
    print processId
    variables = thisProcess.getVariables()
    
    for outfile, dataType in zip(files, dataTypes):
        logicalPath = ('/ASP/OpsSim2/FlareMonitoring/%s:%s' 
                       % (dataType, outfile))
        print logicalPath
        filePath = '%s/%s' % (OUTPUTDIR, outfile)
        print filePath
        attributes = ('nProcessId=%s:nMetStart=%i:nMetStop=%i' 
                       % (processId,TSTART,TSTOP))
        print attributes
        datacatalog.registerDataset(dataType, logicalPath, 
                                    filePath, attributes)
    ]]></script>
    <depends>
      <after process="runpgw" status="SUCCESS"/>
    </depends>
  </process>

  <process name="build_lc_db">
    <job executable="${PGWAVEROOT}/${BINDIR}/build_lc_db.sh"
         batchOptions=" -q medium"/>
    <depends>
      <after process="registerData" status="SUCCESS"/>
    </depends>
  </process>

</task><!--PGWave-->

</pipeline>
