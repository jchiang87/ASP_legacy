<?xml version="1.0" encoding="UTF-8"?>
<pipeline
   xmlns="http://glast-ground.slac.stanford.edu/pipeline"
   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
   xsi:schemaLocation="http://glast-ground.slac.stanford.edu/pipeline http://glast-ground.slac.stanford.edu/Pipeline-II/schemas/2.0/pipeline.xsd">
<!-- $Header$
-->
<task name="DRP_monitoring" version="8.6" type="Data">
  <variables>
    <!-- Default values that can be overridden at the command line. -->
    <var name="BINDIR">rh9_gcc32</var>
    <var name="datacatalog_imp">datacatalog</var>
    <var name="pgwave_folder">/ASP/Results/pgwave</var>
    <var name="outputFolder">/ASP/Results/DRP</var>
    <var name="xrootd_folder">/ASP/DRP</var>
    <var name="GALPROP_MODEL">/afs/slac/g/glast/ground/ASP/GALPROP_MODEL/gll_iem_v01.fit</var>
  </variables>
  <prerequisites>
    <prerequisite name="OUTPUTDIR" type="string"/>
    <prerequisite name="logicalPath" type="string"/>
    <prerequisite name="interval" type="integer"/>
    <prerequisite name="frequency" type="string"/>
    <prerequisite name="TSTART" type="string"/>
    <prerequisite name="TSTOP" type="string"/>
    <prerequisite name="pgwave_streamId" type="integer"/>
    <prerequisite name="ASP_PATH" type="string"/>
    <prerequisite name="DRPMONITORINGROOT" type="string"/>
  </prerequisites>

  <process name="catalogQuery">
    <script><![CDATA[
      print "using datacatalog implementation: ", datacatalog_imp
      datacat = eval(datacatalog_imp)
      #
      # Query for the FT1/2 files for this time interval.
      #
      def query(outfile, path, TSTART, TSTOP):
          output = pipeline.createFile(outfile)
          opt1 = '(%(TSTART)i <= nMetStart && nMetStop <= %(TSTOP)i)' % locals()
          opt2 = '(nMetStart <= %(TSTART)i && %(TSTART)i <= nMetStop)'%locals()
          opt3 = '(nMetStart <= %(TSTOP)i && %(TSTOP)i <= nMetStop)' % locals()
          query = ('DataType == \"%s\" && (%s || %s || %s)' 
                   % (path, opt1, opt2, opt3))
          datasetList = datacat.getDatasets(logicalPath+'/*', query)
          datasetList.writeToFile(output, 1)
          pipeline.writeFile(output)
      query("Ft1FileList", "FT1", TSTART, TSTOP)
      query("Ft2FileList", "FT2", TSTART, TSTOP)
      #
      # Find the location of the source list prepared by pgwave.
      #
      output = pipeline.createFile('pgwaveFileList')
      query = ('DataType==\"PGWAVESOURCELIST\" && nDatasetId==%i' 
               % pgwave_streamId)
      logicalPath = '%s/%s' % (pgwave_folder, frequency)
      datasetList = datacat.getDatasets(logicalPath+'/*', query)
      datasetList.writeToFile(output, 1)
      pipeline.writeFile(output)
      ]]>
    </script>
  </process>

  <process name="getIntervalData" autoRetryMaxAttempts="2">
    <job executable="${DRPMONITORINGROOT}/${BINDIR}/getIntervalData.sh" 
         batchOptions=" -q glastdataq " allocationGroup="glastdata" />
    <depends>
      <after process="catalogQuery" status="SUCCESS"/>
    </depends>
  </process>

  <process name="diffuseResponses" autoRetryMaxAttempts="2">
    <job executable="${DRPMONITORINGROOT}/${BINDIR}/diffuseResponses.sh"
         batchOptions=" -q medium " allocationGroup="glastdata" />
    <depends>
      <after process="getIntervalData" status="SUCCESS"/>
    </depends>
  </process>

  <process name="sourceSelection" autoRetryMaxAttempts="2">
    <job executable="${DRPMONITORINGROOT}/${BINDIR}/sourceSelection.sh"
         batchOptions=" -q glastdataq " allocationGroup="glastdata" />
    <depends>
      <after process="getIntervalData" status="SUCCESS"/>
    </depends>
  </process>

  <process name="assignRois" autoRetryMaxAttempts="2">
    <job executable="${DRPMONITORINGROOT}/${BINDIR}/assignRois.sh"
         batchOptions=" -q glastdataq " allocationGroup="glastdata" />
    <depends>
      <after process="sourceSelection" status="SUCCESS"/>
    </depends>
  </process>

  <process name="launchRoiAnalyses" autoRetryMaxAttempts="2">
    <script language="python">
      <![CDATA[
        assignRois = pipeline.getProcessInstance("assignRois")
        roi_ids = ("%s" % assignRois.getVariable("ROI_IDS")).split()
        roi_ids = [int(x) for x in roi_ids]
        print "number of ROIs", len(roi_ids)
        for id in roi_ids:
            pipeline.createSubstream("roiAnalysis", id)
      ]]>
    </script>
    <depends>
      <after process="diffuseResponses" status="SUCCESS"/>
      <after process="assignRois" status="SUCCESS"/>
    </depends>
    <createsSubtasks>
      <subtask>roiAnalysis</subtask>
    </createsSubtasks>
  </process>

  <process name="createArchive" autoRetryMaxAttempts="1">
    <job executable="${DRPMONITORINGROOT}/${BINDIR}/createTarBall.sh"
         batchOptions=" -q glastdataq " allocationGroup="glastdata" />
    <depends>
      <after process="roiAnalysis.dummyProcess" status="SUCCESS"/>
    </depends>
  </process>

  <process name="registerArchive">
    <script language="python">
      <![CDATA[
        createArchive = pipeline.getProcessInstance("createArchive")
        dataType = "DRP_ARCHIVE"

        filePath = createArchive.getVariable("tarball_name")

        attributes = ('nMetStart=%s:nMetStop=%s:sFrequency=%s:nInterval=%i' %
                      (TSTART, TSTOP, frequency, interval))
        print attributes

        outfile = filePath.split('/')[-1]
        logicalPath = '%s/%s:%s' % (outputFolder, dataType, outfile)
        print logicalPath

        if filePath.find('root') == 0:
            filePath += "@SLAC_XROOT"
        print filePath

        datacatalog.registerDataset(dataType, logicalPath, filePath,
                                    attributes)
      ]]>
    </script>
    <depends>
      <after process="createArchive" status="SUCCESS"/>
    </depends>
  </process>

  <process name="clean_up_files" autoRetryMaxAttempts="1">
    <job executable="${DRPMONITORINGROOT}/${BINDIR}/drp_clean_up_files.sh"
         batchOptions=" -q glastdataq " allocationGroup="glastdata" />
    <depends>
      <after process="registerArchive" status="SUCCESS"/>
    </depends>
  </process>
    
  <task name="roiAnalysis" version="1.0" type="Data">
    <process name="getRoiData" autoRetryMaxAttempts="2">
      <variables>
        <var name="ROI_ID">${pipeline.stream}</var>
      </variables>
      <job executable="${DRPMONITORINGROOT}/${BINDIR}/getRoiData.sh" 
           batchOptions=" -q glastdataq " allocationGroup="glastdata" />
    </process>

    <process name="exposureMap" autoRetryMaxAttempts="1">
      <variables>
        <var name="ROI_ID">${pipeline.stream}</var>
      </variables>
      <script language="python">
        <![CDATA[
          args = "ROI_ID=%i" % pipeline.stream
          #submaps = 4
          submaps = 1
          for i in range(submaps):
              pipeline.createSubstream("exposureSubMap", i+1, args)
        ]]>
      </script>
      <depends>
        <after process="getRoiData" status="SUCCESS"/>
      </depends>
      <createsSubtasks>
        <subtask>exposureSubMap</subtask>
      </createsSubtasks>
    </process>

    <process name="combineExpMaps" autoRetryMaxAttempts="2">
      <variables>
        <var name="ROI_ID">${pipeline.stream}</var>
      </variables>
      <job executable="${DRPMONITORINGROOT}/${BINDIR}/combineDrpExpMaps.sh" 
           batchOptions=" -q express " allocationGroup="glastdata" />
      <depends>
        <after process="exposureSubMap.drpExpMap" status="SUCCESS"/>
      </depends>
    </process>

    <process name="sourceAnalysis" autoRetryMaxAttempts="2">
      <variables>
        <var name="ROI_ID">${pipeline.stream}</var>
      </variables>
      <job executable="${DRPMONITORINGROOT}/${BINDIR}/sourceAnalysis.sh"
           batchOptions=" -q glastdataq " allocationGroup="glastdata" />
      <depends>
        <after process="combineExpMaps" status="SUCCESS"/>
      </depends>
    </process>

    <process name="launchEnergyBandAnalyses">
      <script language="python">
        <![CDATA[
          parent_process = pipeline.getProcessInstance("sourceAnalysis")
          ids = parent_process.getVariable('EBAND_IDS').split()
          emins = parent_process.getVariable('MINIMUM_ENERGIES').split()
          emaxs = parent_process.getVariable('MAXIMUM_ENERGIES').split()
          for i, id, emin, emax in zip(range(len(emins)), ids, emins, emaxs):
              args = "eband_id=%s,emin=%s,emax=%s,ROI_ID=%i" % (id, emin, emax,
                                                                pipeline.stream)
              pipeline.createSubstream("energyBandAnalysis", i, args)
        ]]>
      </script>
      <depends>
        <after process="sourceAnalysis" status="SUCCESS"/>
      </depends>
      <createsSubtasks>
        <subtask>energyBandAnalysis</subtask>
      </createsSubtasks>
    </process>

    <process name="dummyProcess" autoRetryMaxAttempts="1">
      <script language="python">
        <![CDATA[
           print "energyBandAnalysis.fitEnergyBand processes finished"
        ]]>
      </script>
      <depends>
        <after process="energyBandAnalysis.fitEnergyBand" status="SUCCESS"/>
      </depends>
    </process> 

    <task name="exposureSubMap" version="1.0" type="Data">
      <prerequisites>
        <prerequisite name="ROI_ID" type="string"/>
      </prerequisites>
      <process name="drpExpMap" autoRetryMaxAttempts="1">
        <variables>
          <var name="EXPMAP_ID">${pipeline.stream}</var>
        </variables>
        <job executable="${DRPMONITORINGROOT}/${BINDIR}/drpExpMap.sh"
             batchOptions=" -q glastdataq " allocationGroup="glastdata" />
      </process>
    </task> <!--exposureSubMap-->

    <task name="energyBandAnalysis" version="1.0" type="Data">
      <prerequisites>
        <prerequisite name="eband_id" type="integer"/>
        <prerequisite name="emin" type="integer"/>
        <prerequisite name="emax" type="integer"/>
        <prerequisite name="ROI_ID" type="string"/>
      </prerequisites>
      <process name="fitEnergyBand" autoRetryMaxAttempts="2">
        <job executable="${DRPMONITORINGROOT}/${BINDIR}/fitEnergyBand.sh"
             batchOptions=" -q glastdataq " allocationGroup="glastdata" />
      </process>
    </task> <!--energyBandAnalysis-->

  </task> <!--roiAnalysis-->

</task> <!--DRP_monitoring-->

</pipeline>
